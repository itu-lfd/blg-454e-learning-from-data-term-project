{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20204c0c-4a09-4d32-89b3-60c3bfcf7204",
   "metadata": {},
   "source": [
    "__Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e068e683-7cfa-4d86-8a7b-df15fc4413a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from helpers import read_csv_with_pandas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab41c2fc-111c-4258-964a-f6c025a28fce",
   "metadata": {},
   "source": [
    "__Reading CSV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c9c6a94-9ba7-42b8-8b87-5f616723f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/aps_failure_training_set.csv')\n",
    "df_test = pd.read_csv('data/aps_failure_test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63096efe-2698-4c72-83d4-f42ca247fd53",
   "metadata": {},
   "source": [
    "__Replace Nan Values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4998509-5059-476d-b42a-ad9c59102743",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['class'] = df_train['class'].replace(['pos','neg'],[1,0])\n",
    "df_train = df_train.replace('na',np.NaN)\n",
    "\n",
    "df_test['class'] = df_test['class'].replace(['pos','neg'],[1,0])\n",
    "df_test = df_test.replace('na',np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb98ae-5477-45fd-9633-b56276f26327",
   "metadata": {},
   "source": [
    "__Deleting Features With Zero Variance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44bfa3c5-062f-488a-8546-9dcf62c12736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature with zero variance is :  cd_000\n",
      "The feature with zero variance is :  cd_000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16000, 170)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.astype(float)\n",
    "for i in df_train:\n",
    "  if df_train[i].std() == 0:\n",
    "    df_train = df_train.drop([i],axis=1)\n",
    "    print('The feature with zero variance is : ',i)\n",
    "df_train.shape\n",
    "\n",
    "df_test = df_test.astype(float)\n",
    "for i in df_test:\n",
    "  if df_test[i].std() == 0:\n",
    "    df_test = df_test.drop([i],axis=1)\n",
    "    print('The feature with zero variance is : ',i)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23559924-47bb-41f6-94d2-284cf2831517",
   "metadata": {},
   "source": [
    "__Deleting Duplicates__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f45424d-b88e-424d-bc1d-3f31fcd1640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 170)\n",
      "(16000, 170)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop_duplicates(keep = 'first')\n",
    "df_train = df_train.T.drop_duplicates().T\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = df_test.drop_duplicates(keep = 'first')\n",
    "df_test = df_test.T.drop_duplicates().T\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854a9d8-fa33-463b-afa8-bd27a287f36e",
   "metadata": {},
   "source": [
    "__Calculating Missing Values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "60c35f09-e17f-4612-9110-fbdf2e739ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_feature_count = dict(df_train.drop('class',axis=1).isnull().sum())\n",
    "missing_feature_count = dict(sorted(missing_feature_count.items(), key=lambda item:item[1],reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a74cdc-52b1-4f85-a051-95ea73384510",
   "metadata": {},
   "source": [
    "__Missing Value Imputation__\n",
    "\n",
    "We will eliminate features with missing value greater than 60%.\n",
    "\n",
    "We will perform median imputation of features with missing values less than 20%\n",
    "\n",
    "For the features between 20%-60% missing values, we will perform model based imputation called MICE imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c0089f3-5820-4360-9062-466a1e272cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features to be eliminated :  ['br_000', 'bq_000', 'bp_000', 'bo_000', 'ab_000', 'cr_000', 'bn_000', 'bm_000']\n",
      "Number of features to be eliminated :  8\n",
      "\n",
      "Features for model imputation :  ['bl_000', 'bk_000', 'ad_000', 'cf_000', 'cg_000', 'ch_000', 'co_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000']\n",
      "Number of features for model imputation :  16\n",
      "\n",
      "Features for median imputaton :  ['ec_00', 'cm_000', 'cl_000', 'ed_000', 'ak_000', 'ca_000', 'dm_000', 'df_000', 'dg_000', 'dh_000', 'dl_000', 'dj_000', 'dk_000', 'eb_000', 'di_000', 'ac_000', 'bx_000', 'cc_000', 'bd_000', 'ds_000', 'dt_000', 'dp_000', 'dq_000', 'dr_000', 'du_000', 'dv_000', 'bc_000', 'cp_000', 'de_000', 'do_000', 'dy_000', 'ef_000', 'ar_000', 'bz_000', 'dx_000', 'dz_000', 'ea_000', 'eg_000', 'be_000', 'dd_000', 'ce_000', 'ax_000', 'ae_000', 'af_000', 'av_000', 'bf_000', 'bs_000', 'cb_000', 'bu_000', 'bv_000', 'cq_000', 'dn_000', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009', 'ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ah_000', 'bb_000', 'al_000', 'an_000', 'ap_000', 'bg_000', 'bh_000', 'ai_000', 'aj_000', 'am_0', 'as_000', 'at_000', 'au_000', 'ao_000', 'aq_000', 'bi_000', 'bj_000', 'by_000', 'ci_000', 'cj_000', 'ck_000', 'bt_000', 'aa_000']\n",
      "Number of features for median imputaton :  145\n"
     ]
    }
   ],
   "source": [
    "features_tobe_eliminated = []\n",
    "median_imp_features = []\n",
    "model_imp_features = []\n",
    "for i in missing_feature_count.keys():\n",
    "  percent = (missing_feature_count[i]/df_train.shape[0])\n",
    "  if percent > 0.6:\n",
    "    features_tobe_eliminated.append(i)\n",
    "  elif percent < 0.2:\n",
    "    median_imp_features.append(i)\n",
    "  else:\n",
    "    model_imp_features.append(i)\n",
    "\n",
    "print(\"Features to be eliminated : \",features_tobe_eliminated)\n",
    "print(\"Number of features to be eliminated : \",len(features_tobe_eliminated))\n",
    "print(\"\\nFeatures for model imputation : \",model_imp_features)\n",
    "print(\"Number of features for model imputation : \",len(model_imp_features))\n",
    "print(\"\\nFeatures for median imputaton : \",median_imp_features)\n",
    "print(\"Number of features for median imputaton : \",len(median_imp_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d54a5660-1966-4689-aa3c-e070b9679350",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('class',axis=1)\n",
    "y = df_train['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed9a6ae-1656-41d1-b5b8-aee1c1569aa6",
   "metadata": {},
   "source": [
    "__Train & CV Split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "501dddfe-797d-4f94-a368-f40d086224bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Train Data ==========\n",
      "(41999, 169)\n",
      "(41999,)\n",
      "========== CV Data ==========\n",
      "(18000, 169)\n",
      "(18000,)\n",
      "========== Test Data ==========\n",
      "(16000, 169)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_test = df_test.drop('class',axis=1)\n",
    "y_test = df_test['class']\n",
    "\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "X_cv.reset_index(drop=True,inplace=True)\n",
    "y_cv.reset_index(drop=True,inplace=True)\n",
    "print(10*'='+\" Train Data \"+10*'=')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(10*'='+\" CV Data \"+10*'=')\n",
    "print(X_cv.shape)\n",
    "print(y_cv.shape)\n",
    "\n",
    "print(10*'='+\" Test Data \"+10*'=')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8efdff-2bd2-4d2b-991a-4551519153a3",
   "metadata": {},
   "source": [
    "__Median Imputation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5bf28bbf-37fd-4355-8369-743021622ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(strategy='median')\n",
    "median_imputer.fit(X_train[median_imp_features])\n",
    "\n",
    "X_train_median = median_imputer.transform(X_train[median_imp_features])\n",
    "X_cv_median = median_imputer.transform(X_cv[median_imp_features])\n",
    "X_test_median = median_imputer.transform(X_test[median_imp_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6ea9008-0cd7-4964-91eb-9850cbb20741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41999, 161)\n",
      "(18000, 161)\n",
      "(16000, 161)\n"
     ]
    }
   ],
   "source": [
    "X_train_mice = X_train.copy()\n",
    "X_train_mice[median_imp_features] = X_train_median\n",
    "X_train_mice = X_train_mice.drop(features_tobe_eliminated,axis=1)\n",
    "print(X_train_mice.shape)\n",
    "\n",
    "X_cv_mice = X_cv.copy()\n",
    "X_cv_mice[median_imp_features] = X_cv_median\n",
    "X_cv_mice = X_cv_mice.drop(features_tobe_eliminated,axis=1)\n",
    "print(X_cv_mice.shape)\n",
    "\n",
    "X_test_mice = X_test.copy()\n",
    "X_test_mice[median_imp_features] = X_test_median\n",
    "X_test_mice = X_test_mice.drop(features_tobe_eliminated,axis=1)\n",
    "print(X_test_mice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed004c-656d-43c4-8371-0a10458b2680",
   "metadata": {},
   "source": [
    "__Median Imputation for Mice Part (Mice runs to slow)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28451a6c-08e4-4a7b-994e-92eb50705484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_imputation(df):\n",
    "    median_imputer = SimpleImputer(strategy='median')\n",
    "    median_imputer.fit(df)\n",
    "    df_imputed = median_imputer.transform(df)\n",
    "    #df_imputed = pd.DataFrame(df_imputed,columns=df.columns)\n",
    "    return df_imputed, median_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "175b38e5-838d-4873-aeee-47d1a04babc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed, median_imputer = median_imputation(X_train_mice)\n",
    "X_cv_imputed = median_imputer.transform(X_cv_mice)\n",
    "X_test_imputed = median_imputer.transform(X_test_mice)\n",
    "\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train_mice.columns)\n",
    "X_cv_imputed = pd.DataFrame(X_cv_imputed, columns=X_cv_mice.columns)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test_mice.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a75537-508a-4f8a-902a-dc2e312d7e05",
   "metadata": {},
   "source": [
    "__Mice Imputation #Do not Use__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f64cb9e-fdc6-485b-baf5-4377fb085bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    x = df\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    return x_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05ecc2f2-0614-4641-a26a-68e76f2e06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, scaler = normalize(X_train_mice)\n",
    "X_cv_scaled = scaler.transform(X_cv_mice)\n",
    "X_test_scaled = scaler.transform(X_test_mice)\n",
    "\n",
    "X_train_mice = pd.DataFrame(X_train_scaled, columns= X_train_mice.columns)\n",
    "X_cv_mice = pd.DataFrame(X_cv_scaled, columns= X_cv_mice.columns)\n",
    "X_test_mice = pd.DataFrame(X_test_scaled, columns= X_test_mice.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "509ab75e-358d-4040-9316-d92093d3f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mice_imputation(df):\n",
    "  mice_imputer = IterativeImputer(random_state=42, max_iter=10)\n",
    "  mice_imputer.fit(df)\n",
    "  df_imputed = mice_imputer.transform(df)\n",
    "  #df_imputed = pd.DataFrame(df_imputed,columns=df.columns)\n",
    "  return df_imputed, mice_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7e5a5cc-c735-4bd6-94ca-2e47231cc212",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train_imputed, mice_imputer \u001b[38;5;241m=\u001b[39m \u001b[43mmice_imputation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_mice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m X_cv_imputed \u001b[38;5;241m=\u001b[39m mice_imputer\u001b[38;5;241m.\u001b[39mtransform(X_cv_mice)\n\u001b[0;32m      3\u001b[0m X_test_imputed \u001b[38;5;241m=\u001b[39m mice_imputer\u001b[38;5;241m.\u001b[39mtransform(X_test_mice)\n",
      "Cell \u001b[1;32mIn[53], line 3\u001b[0m, in \u001b[0;36mmice_imputation\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmice_imputation\u001b[39m(df):\n\u001b[0;32m      2\u001b[0m   mice_imputer \u001b[38;5;241m=\u001b[39m IterativeImputer(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m   \u001b[43mmice_imputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m   df_imputed \u001b[38;5;241m=\u001b[39m mice_imputer\u001b[38;5;241m.\u001b[39mtransform(df)\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;66;03m#df_imputed = pd.DataFrame(df_imputed,columns=df.columns)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_iterative.py:875\u001b[0m, in \u001b[0;36mIterativeImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the imputer on `X` and return self.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 875\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_iterative.py:761\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat_idx \u001b[38;5;129;01min\u001b[39;00m ordered_idx:\n\u001b[0;32m    758\u001b[0m     neighbor_feat_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_neighbor_feat_idx(\n\u001b[0;32m    759\u001b[0m         n_features, feat_idx, abs_corr_mat\n\u001b[0;32m    760\u001b[0m     )\n\u001b[1;32m--> 761\u001b[0m     Xt, estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impute_one_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_missing_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneighbor_feat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    769\u001b[0m     estimator_triplet \u001b[38;5;241m=\u001b[39m _ImputerTriplet(\n\u001b[0;32m    770\u001b[0m         feat_idx, neighbor_feat_idx, estimator\n\u001b[0;32m    771\u001b[0m     )\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimputation_sequence_\u001b[38;5;241m.\u001b[39mappend(estimator_triplet)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_iterative.py:408\u001b[0m, in \u001b[0;36mIterativeImputer._impute_one_feature\u001b[1;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[0;32m    398\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[0;32m    399\u001b[0m         _safe_indexing(X_filled, neighbor_feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[0;32m    401\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    402\u001b[0m     )\n\u001b[0;32m    403\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[0;32m    404\u001b[0m         _safe_indexing(X_filled, feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[0;32m    406\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    407\u001b[0m     )\n\u001b[1;32m--> 408\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# if no missing values, don't predict\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(missing_row_mask) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_bayes.py:341\u001b[0m, in \u001b[0;36mBayesianRidge.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    338\u001b[0m eigen_vals_ \u001b[38;5;241m=\u001b[39m S\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# Convergence loop of the bayesian ridge regression\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;66;03m# update posterior mean coef_ based on alpha_ and lambda_ and\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;66;03m# compute corresponding rmse\u001b[39;00m\n\u001b[0;32m    344\u001b[0m     coef_, rmse_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_coef_(\n\u001b[0;32m    345\u001b[0m         X, y, n_samples, n_features, XT_y, U, Vh, eigen_vals_, alpha_, lambda_\n\u001b[0;32m    346\u001b[0m     )\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_score:\n\u001b[0;32m    348\u001b[0m         \u001b[38;5;66;03m# compute the log marginal likelihood\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_imputed, mice_imputer = mice_imputation(X_train_mice)\n",
    "X_cv_imputed = mice_imputer.transform(X_cv_mice)\n",
    "X_test_imputed = mice_imputer.transform(X_test_mice)\n",
    "\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train_mice.columns)\n",
    "X_cv_imputed = pd.DataFrame(X_cv_imputed, columns=X_cv_mice.columns)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test_mice.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f017e-c277-4a7b-ab48-5f45c73a9d48",
   "metadata": {},
   "source": [
    "__LDA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3edfa1a6-83fa-4bad-98cf-88c6e5bb52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "\n",
    "# Fit the LDA model with the normalized features and target variable\n",
    "lda.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Transform the features using the fitted LDA model\n",
    "x_train_lda = lda.transform(X_train_imputed)\n",
    "x_test_lda = lda.transform(X_test_imputed)\n",
    "\n",
    "lda_df = pd.DataFrame(data=x_train_lda, columns=['LDA_Component_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881886c-cf1d-4aab-b6fe-763564459fd4",
   "metadata": {},
   "source": [
    "__Finding Best Parameters For Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4c96130c-dd99-4de1-a529-8d2f6feacf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "{'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "max_depth = [5, 10,20, 50]\n",
    "n_estimators = [10,25,50,80,100]\n",
    "min_samples_split = [2,5,10,50]\n",
    "param = {'max_depth':max_depth,'n_estimators':n_estimators,'min_samples_split':min_samples_split}\n",
    "clf = RandomForestClassifier(class_weight = 'balanced' , random_state=42)\n",
    "tuning = RandomizedSearchCV(estimator=clf,param_distributions=param,cv=3,scoring='f1_macro',n_jobs=-1,return_train_score=True,verbose=10)\n",
    "tuning.fit(x_train_lda,y_train)\n",
    "best = tuning.best_params_\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919acad-43a4-4095-bc5d-6fc74eabfb7b",
   "metadata": {},
   "source": [
    "__Random Forest Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8419bdb8-6bdd-4300-92bc-d0974dbb3774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro average f1-score on Train Data :  0.9146447628337403\n",
      "Macro average f1-score on Test Data :  0.8506033509439714\n"
     ]
    }
   ],
   "source": [
    "best_RF_model = RandomForestClassifier(max_depth = 20, n_estimators =100 ,min_samples_split=10,n_jobs=-1,class_weight = 'balanced' , random_state=42, criterion='gini')\n",
    "calib_RF = CalibratedClassifierCV(estimator=best_RF_model, cv=3, method='sigmoid')\n",
    "calib_RF.fit(x_train_lda,y_train)\n",
    "\n",
    "y_pred = calib_RF.predict(x_train_lda)\n",
    "f1_scr = f1_score(y_train,y_pred, average = 'macro')\n",
    "print(\"Macro average f1-score on Train Data : \", f1_scr)\n",
    "\n",
    "y_pred = calib_RF.predict(x_test_lda)\n",
    "f1_scr = f1_score(y_test,y_pred, average = 'macro')\n",
    "print(\"Macro average f1-score on Test Data : \", f1_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa47ca-b631-4cb6-aca8-a1d957000b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
