{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20204c0c-4a09-4d32-89b3-60c3bfcf7204",
   "metadata": {},
   "source": [
    "__Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e068e683-7cfa-4d86-8a7b-df15fc4413a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from helpers import read_csv_with_pandas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab41c2fc-111c-4258-964a-f6c025a28fce",
   "metadata": {},
   "source": [
    "__Reading CSV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9c6a94-9ba7-42b8-8b87-5f616723f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/aps_failure_training_set.csv')\n",
    "df_test = pd.read_csv('data/aps_failure_test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63096efe-2698-4c72-83d4-f42ca247fd53",
   "metadata": {},
   "source": [
    "__Replace Nan Values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4998509-5059-476d-b42a-ad9c59102743",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['class'] = df_train['class'].replace(['pos','neg'],[1,0])\n",
    "df_train = df_train.replace('na',np.NaN)\n",
    "\n",
    "df_test['class'] = df_test['class'].replace(['pos','neg'],[1,0])\n",
    "df_test = df_test.replace('na',np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb98ae-5477-45fd-9633-b56276f26327",
   "metadata": {},
   "source": [
    "__Deleting Features With Zero Variance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44bfa3c5-062f-488a-8546-9dcf62c12736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature with zero variance is :  cd_000\n",
      "The feature with zero variance is :  cd_000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16000, 170)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.astype(float)\n",
    "for i in df_train:\n",
    "  if df_train[i].std() == 0:\n",
    "    df_train = df_train.drop([i],axis=1)\n",
    "    print('The feature with zero variance is : ',i)\n",
    "df_train.shape\n",
    "\n",
    "df_test = df_test.astype(float)\n",
    "for i in df_test:\n",
    "  if df_test[i].std() == 0:\n",
    "    df_test = df_test.drop([i],axis=1)\n",
    "    print('The feature with zero variance is : ',i)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23559924-47bb-41f6-94d2-284cf2831517",
   "metadata": {},
   "source": [
    "__Deleting Duplicates__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f45424d-b88e-424d-bc1d-3f31fcd1640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 170)\n",
      "(16000, 170)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop_duplicates(keep = 'first')\n",
    "df_train = df_train.T.drop_duplicates().T\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = df_test.drop_duplicates(keep = 'first')\n",
    "df_test = df_test.T.drop_duplicates().T\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854a9d8-fa33-463b-afa8-bd27a287f36e",
   "metadata": {},
   "source": [
    "__Calculating Missing Values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c35f09-e17f-4612-9110-fbdf2e739ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_feature_count = dict(df_train.drop('class',axis=1).isnull().sum())\n",
    "missing_feature_count = dict(sorted(missing_feature_count.items(), key=lambda item:item[1],reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a74cdc-52b1-4f85-a051-95ea73384510",
   "metadata": {},
   "source": [
    "__Missing Value Imputation__\n",
    "\n",
    "We will eliminate features with missing value greater than 60%.\n",
    "\n",
    "We will perform median imputation of features with missing values less than 20%\n",
    "\n",
    "For the features between 20%-60% missing values, we will perform model based imputation called MICE imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0089f3-5820-4360-9062-466a1e272cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features to be eliminated :  ['br_000', 'bq_000', 'bp_000', 'bo_000', 'ab_000', 'cr_000', 'bn_000', 'bm_000']\n",
      "Number of features to be eliminated :  8\n",
      "\n",
      "Features for model imputation :  ['bl_000', 'bk_000', 'ad_000', 'cf_000', 'cg_000', 'ch_000', 'co_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000']\n",
      "Number of features for model imputation :  16\n",
      "\n",
      "Features for median imputaton :  ['ec_00', 'cm_000', 'cl_000', 'ed_000', 'ak_000', 'ca_000', 'dm_000', 'df_000', 'dg_000', 'dh_000', 'dl_000', 'dj_000', 'dk_000', 'eb_000', 'di_000', 'ac_000', 'bx_000', 'cc_000', 'bd_000', 'ds_000', 'dt_000', 'dp_000', 'dq_000', 'dr_000', 'du_000', 'dv_000', 'bc_000', 'cp_000', 'de_000', 'do_000', 'dy_000', 'ef_000', 'ar_000', 'bz_000', 'dx_000', 'dz_000', 'ea_000', 'eg_000', 'be_000', 'dd_000', 'ce_000', 'ax_000', 'ae_000', 'af_000', 'av_000', 'bf_000', 'bs_000', 'cb_000', 'bu_000', 'bv_000', 'cq_000', 'dn_000', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009', 'ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ah_000', 'bb_000', 'al_000', 'an_000', 'ap_000', 'bg_000', 'bh_000', 'ai_000', 'aj_000', 'am_0', 'as_000', 'at_000', 'au_000', 'ao_000', 'aq_000', 'bi_000', 'bj_000', 'by_000', 'ci_000', 'cj_000', 'ck_000', 'bt_000', 'aa_000']\n",
      "Number of features for median imputaton :  145\n"
     ]
    }
   ],
   "source": [
    "features_tobe_eliminated = []\n",
    "median_imp_features = []\n",
    "model_imp_features = []\n",
    "for i in missing_feature_count.keys():\n",
    "  percent = (missing_feature_count[i]/df_train.shape[0])\n",
    "  if percent > 0.6:\n",
    "    features_tobe_eliminated.append(i)\n",
    "  elif percent < 0.2:\n",
    "    median_imp_features.append(i)\n",
    "  else:\n",
    "    model_imp_features.append(i)\n",
    "\n",
    "print(\"Features to be eliminated : \",features_tobe_eliminated)\n",
    "print(\"Number of features to be eliminated : \",len(features_tobe_eliminated))\n",
    "print(\"\\nFeatures for model imputation : \",model_imp_features)\n",
    "print(\"Number of features for model imputation : \",len(model_imp_features))\n",
    "print(\"\\nFeatures for median imputaton : \",median_imp_features)\n",
    "print(\"Number of features for median imputaton : \",len(median_imp_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed9a6ae-1656-41d1-b5b8-aee1c1569aa6",
   "metadata": {},
   "source": [
    "__Train & CV Split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54a5660-1966-4689-aa3c-e070b9679350",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('class',axis=1)\n",
    "y = df_train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "501dddfe-797d-4f94-a368-f40d086224bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Train Data ==========\n",
      "(41999, 169)\n",
      "(41999,)\n",
      "========== CV Data ==========\n",
      "(18000, 169)\n",
      "(18000,)\n",
      "========== Test Data ==========\n",
      "(16000, 169)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_test = df_test.drop('class',axis=1)\n",
    "y_test = df_test['class']\n",
    "\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "X_cv.reset_index(drop=True,inplace=True)\n",
    "y_cv.reset_index(drop=True,inplace=True)\n",
    "print(10*'='+\" Train Data \"+10*'=')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(10*'='+\" CV Data \"+10*'=')\n",
    "print(X_cv.shape)\n",
    "print(y_cv.shape)\n",
    "\n",
    "print(10*'='+\" Test Data \"+10*'=')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8efdff-2bd2-4d2b-991a-4551519153a3",
   "metadata": {},
   "source": [
    "__Median Imputation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bf28bbf-37fd-4355-8369-743021622ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(strategy='median')\n",
    "median_imputer.fit(X_train[median_imp_features])\n",
    "\n",
    "X_train_median = median_imputer.transform(X_train[median_imp_features])\n",
    "X_cv_median = median_imputer.transform(X_cv[median_imp_features])\n",
    "X_test_median = median_imputer.transform(X_test[median_imp_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6ea9008-0cd7-4964-91eb-9850cbb20741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41999, 161)\n",
      "(18000, 161)\n",
      "(16000, 161)\n"
     ]
    }
   ],
   "source": [
    "X_train_mice = X_train.copy()\n",
    "X_train_mice[median_imp_features] = X_train_median\n",
    "X_train_mice = X_train_mice.drop(features_tobe_eliminated,axis=1)\n",
    "print(X_train_mice.shape)\n",
    "\n",
    "X_cv_mice = X_cv.copy()\n",
    "X_cv_mice[median_imp_features] = X_cv_median\n",
    "X_cv_mice = X_cv_mice.drop(features_tobe_eliminated,axis=1)\n",
    "print(X_cv_mice.shape)\n",
    "\n",
    "X_test_mice = X_test.copy()\n",
    "X_test_mice[median_imp_features] = X_test_median\n",
    "X_test_mice = X_test_mice.drop(features_tobe_eliminated,axis=1)\n",
    "print(X_test_mice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed004c-656d-43c4-8371-0a10458b2680",
   "metadata": {},
   "source": [
    "__Median Imputation for Mice Part (Mice runs to slow)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28451a6c-08e4-4a7b-994e-92eb50705484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_imputation(df):\n",
    "    median_imputer = SimpleImputer(strategy='median')\n",
    "    median_imputer.fit(df)\n",
    "    df_imputed = median_imputer.transform(df)\n",
    "    #df_imputed = pd.DataFrame(df_imputed,columns=df.columns)\n",
    "    return df_imputed, median_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "175b38e5-838d-4873-aeee-47d1a04babc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed, median_imputer = median_imputation(X_train_mice)\n",
    "X_cv_imputed = median_imputer.transform(X_cv_mice)\n",
    "X_test_imputed = median_imputer.transform(X_test_mice)\n",
    "\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train_mice.columns)\n",
    "X_cv_imputed = pd.DataFrame(X_cv_imputed, columns=X_cv_mice.columns)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test_mice.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a75537-508a-4f8a-902a-dc2e312d7e05",
   "metadata": {},
   "source": [
    "__Mice Imputation #Do not Use__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f64cb9e-fdc6-485b-baf5-4377fb085bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def normalize(df):\\n    x = df\\n    scaler = StandardScaler()\\n    x_scaled = scaler.fit_transform(x)\\n    return x_scaled, scaler'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def normalize(df):\n",
    "    x = df\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    return x_scaled, scaler\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05ecc2f2-0614-4641-a26a-68e76f2e06c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train_scaled, scaler = normalize(X_train_mice)\\nX_cv_scaled = scaler.transform(X_cv_mice)\\nX_test_scaled = scaler.transform(X_test_mice)\\n\\nX_train_mice = pd.DataFrame(X_train_scaled, columns= X_train_mice.columns)\\nX_cv_mice = pd.DataFrame(X_cv_scaled, columns= X_cv_mice.columns)\\nX_test_mice = pd.DataFrame(X_test_scaled, columns= X_test_mice.columns)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_train_scaled, scaler = normalize(X_train_mice)\n",
    "X_cv_scaled = scaler.transform(X_cv_mice)\n",
    "X_test_scaled = scaler.transform(X_test_mice)\n",
    "\n",
    "X_train_mice = pd.DataFrame(X_train_scaled, columns= X_train_mice.columns)\n",
    "X_cv_mice = pd.DataFrame(X_cv_scaled, columns= X_cv_mice.columns)\n",
    "X_test_mice = pd.DataFrame(X_test_scaled, columns= X_test_mice.columns)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "509ab75e-358d-4040-9316-d92093d3f1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def mice_imputation(df):\\n  mice_imputer = IterativeImputer(random_state=42, max_iter=10)\\n  mice_imputer.fit(df)\\n  df_imputed = mice_imputer.transform(df)\\n  #df_imputed = pd.DataFrame(df_imputed,columns=df.columns)\\n  return df_imputed, mice_imputer'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def mice_imputation(df):\n",
    "  mice_imputer = IterativeImputer(random_state=42, max_iter=10)\n",
    "  mice_imputer.fit(df)\n",
    "  df_imputed = mice_imputer.transform(df)\n",
    "  #df_imputed = pd.DataFrame(df_imputed,columns=df.columns)\n",
    "  return df_imputed, mice_imputer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7e5a5cc-c735-4bd6-94ca-2e47231cc212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train_imputed, mice_imputer = mice_imputation(X_train_mice)\\nX_cv_imputed = mice_imputer.transform(X_cv_mice)\\nX_test_imputed = mice_imputer.transform(X_test_mice)\\n\\nX_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train_mice.columns)\\nX_cv_imputed = pd.DataFrame(X_cv_imputed, columns=X_cv_mice.columns)\\nX_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test_mice.columns)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_train_imputed, mice_imputer = mice_imputation(X_train_mice)\n",
    "X_cv_imputed = mice_imputer.transform(X_cv_mice)\n",
    "X_test_imputed = mice_imputer.transform(X_test_mice)\n",
    "\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train_mice.columns)\n",
    "X_cv_imputed = pd.DataFrame(X_cv_imputed, columns=X_cv_mice.columns)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test_mice.columns)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f017e-c277-4a7b-ab48-5f45c73a9d48",
   "metadata": {},
   "source": [
    "__LDA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3edfa1a6-83fa-4bad-98cf-88c6e5bb52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "\n",
    "# Fit the LDA model with the normalized features and target variable\n",
    "lda.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Transform the features using the fitted LDA model\n",
    "x_train_lda = lda.transform(X_train_imputed)\n",
    "x_test_lda = lda.transform(X_test_imputed)\n",
    "\n",
    "lda_df = pd.DataFrame(data=x_train_lda, columns=['LDA_Component_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e961e22c-bff1-4052-8924-790defef8a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9891875\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99     15625\n",
      "         1.0       0.80      0.72      0.76       375\n",
      "\n",
      "    accuracy                           0.99     16000\n",
      "   macro avg       0.90      0.86      0.88     16000\n",
      "weighted avg       0.99      0.99      0.99     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lda.predict(X_test_imputed)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881886c-cf1d-4aab-b6fe-763564459fd4",
   "metadata": {},
   "source": [
    "__Finding Best Parameters For Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c96130c-dd99-4de1-a529-8d2f6feacf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'n_estimators': 50, 'min_samples_split': 5, 'max_depth': 35}\n"
     ]
    }
   ],
   "source": [
    "max_depth = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "n_estimators = [10, 25, 50, 75, 100, 125, 150, 175, 200]\n",
    "min_samples_split = [2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "param = {'max_depth':max_depth,'n_estimators':n_estimators,'min_samples_split':min_samples_split}\n",
    "clf = RandomForestClassifier(class_weight = 'balanced' , random_state=42)\n",
    "tuning = RandomizedSearchCV(estimator=clf,param_distributions=param,cv=5,scoring='f1_macro',n_jobs=-1,return_train_score=True,verbose=10)\n",
    "tuning.fit(x_train_lda,y_train)\n",
    "best = tuning.best_params_\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919acad-43a4-4095-bc5d-6fc74eabfb7b",
   "metadata": {},
   "source": [
    "__Random Forest Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8419bdb8-6bdd-4300-92bc-d0974dbb3774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro average f1-score on Train Data :  0.9138580786202264\n",
      "Macro average f1-score on Test Data :  0.8494162158966629\n"
     ]
    }
   ],
   "source": [
    "best_RF_model = RandomForestClassifier(max_depth = 25, n_estimators =75 ,min_samples_split=10,n_jobs=-1,class_weight = 'balanced' , random_state=42, criterion='gini')\n",
    "calib_RF = CalibratedClassifierCV(estimator=best_RF_model, cv=3, method='sigmoid')\n",
    "calib_RF.fit(x_train_lda,y_train)\n",
    "\n",
    "y_pred = calib_RF.predict(x_train_lda)\n",
    "f1_scr = f1_score(y_train,y_pred, average = 'macro')\n",
    "print(\"Macro average f1-score on Train Data : \", f1_scr)\n",
    "\n",
    "y_pred = calib_RF.predict(x_test_lda)\n",
    "f1_scr = f1_score(y_test,y_pred, average = 'macro')\n",
    "print(\"Macro average f1-score on Test Data : \", f1_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa47ca-b631-4cb6-aca8-a1d957000b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
